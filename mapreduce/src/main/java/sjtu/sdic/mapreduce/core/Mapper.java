package sjtu.sdic.mapreduce.core;


import com.alibaba.fastjson.JSONArray;
import sjtu.sdic.mapreduce.common.KeyValue;
import sjtu.sdic.mapreduce.common.Utils;

import java.io.*;
import java.nio.charset.StandardCharsets;
import java.nio.file.Files;
import java.util.ArrayList;
import java.util.List;

import java.util.Collections;

/**
 * Created by Cachhe on 2019/4/19.
 */
public class Mapper {

    /**
     * doMap manages one map task: it should read one of the input files
     * {@code inFile}, call the user-defined map function {@code mapF} for
     * that file's contents, and partition mapF's output into {@code nReduce}
     * intermediate files.
     * <p>
     * There is one intermediate file per reduce task. The file name
     * includes both the map task number and the reduce task number. Use
     * the filename generated by {@link Utils#reduceName(String, int, int)}
     * as the intermediate file for reduce task r. RPCCall
     * {@link Mapper#hashCode(String)} on each key, mod nReduce,
     * to pick r for a key/value pair.
     * <p>
     * {@code mapF} is the map function provided by the application. The first
     * argument should be the input file name, though the map function
     * typically ignores it. The second argument should be the entire
     * input file contents. {@code mapF} returns a list containing the
     * key/value pairs for reduce; see {@link KeyValue} for the definition of
     * KeyValue.
     * <p>
     * Look at Java's File and Files API for functions to read
     * and write files.
     * <p>
     * Coming up with a scheme for how to format the key/value pairs on
     * disk can be tricky, especially when taking into account that both
     * keys and values could contain newlines, quotes, and any other
     * character you can think of.
     * <p>
     * One format often used for serializing data to a byte stream that the
     * other end can correctly reconstruct is JSON. You are not required to
     * use JSON, but as the output of the reduce tasks *must* be JSON,
     * familiarizing yourself with it here may prove useful. There're many
     * JSON-lib for Java, and we recommend and supply with FastJSON powered by
     * Alibaba. You can refer to official docs or other resources to figure
     * how to use it.
     * <p>
     * The corresponding decoding functions can be found in {@link Reducer}.
     * <p>
     * Remember to close the file after you have written all the values!
     * <p>
     * Your code here (Part I).
     *
     * @param jobName the name of the MapReduce job
     * @param mapTask which map task this is
     * @param inFile  file name (if in same dir, it's also the file path)
     * @param nReduce the number of reduce task that will be run ("R" in the paper)
     * @param mapF    the user-defined map function
     */
    public static void doMap(String jobName, int mapTask, String inFile, int nReduce, MapFunc mapF) {
        System.out.println(jobName);
        System.out.println(inFile);
        String filecontent = readUTF(inFile);
        // check filecontent
        // System.out.println(filecontent);
        List<KeyValue> kvpairs_list = mapF.map(inFile, filecontent);
        // Sort all the (key, value) data by keys
        // partition the List<KeyValue>
          // printListKV(kvpairs_list);
        // generate  nReduce intermediate file name
        int reduce_num = 0;
        String intermediate_file_name = Utils.reduceName(jobName,mapTask,reduce_num);

        System.out.println(intermediate_file_name);

        //encoded the key/value pairs
        String json_kvpairs= JSONArray.toJSONString(kvpairs_list);

        // create intermediate files Intermediate k/v pairs buffered in memory and periodically written to the local disk
        writeFile(intermediate_file_name,json_kvpairs);
    }
    public static void printListKV(List<KeyValue> kvpairs_list)
    {
        for(KeyValue pair : kvpairs_list) {
            System.out.println(pair.key+":"+pair.value);
        }
    }
    public static void writeFile(String inFile,String content)
    {
        try
        {
            BufferedWriter out = new BufferedWriter(new FileWriter( inFile ));
            out = new BufferedWriter(new FileWriter(inFile,true));
            out.write(content);
            out.flush();
            out.close();
        } catch (UnsupportedEncodingException e)
        {
            System.out.println(e.getMessage());
        } catch (IOException e)
        {
            System.out.println(e.getMessage());
        } catch (Exception e)
        {
            System.out.println(e.getMessage());
        }
    }
    public static String readUTF(String inFile) {
        try {
            File fileDir = new File(inFile);

            BufferedReader in = new BufferedReader(
                    new InputStreamReader(
                            new FileInputStream(fileDir), "UTF8"));

            String str;
            String res = "";

            while ((str = in.readLine()) != null) {
                res = res + str + "\n";
            }
            in.close();
            return res;
        } catch (UnsupportedEncodingException e) {
            System.out.println(e.getMessage());
        } catch (IOException e) {
            System.out.println(e.getMessage());
        } catch (Exception e) {
            System.out.println(e.getMessage());
        }
        return "";
    }

    /**
     * a simple method limiting hash code to be positive
     *
     * @param src string
     * @return a positive hash code
     */
    private static int hashCode(String src) {
        return src.hashCode() & Integer.MAX_VALUE;
    }
}
